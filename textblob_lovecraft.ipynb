{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Sentiment analysis on\n",
    "##H.P. Lovecraft's *The Shunned House*\n",
    "\n",
    "For this, we'll use the TextBlob library (http://textblob.readthedocs.org/en/dev/) and pandas (http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import collections\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've already pulled down *The Sunned House* from Project Gutenberg (https://www.gutenberg.org/wiki/Main_Page) and saved it as a text file called 'lovecraft.txt'.  Here we'll load it then define the encoding as utf-8.  Lastly, we'll instantiate a TextBlob object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open (r'lovecraft.txt', 'r') as myfile:\n",
    "    shunned = myfile.read()\n",
    "\n",
    "ushunned = unicode(shunned, 'utf-8')\n",
    "\n",
    "tb = TextBlob(ushunned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll go through every sentence in the story and get the 'sentiment' of each one.  Sentiment analysis in TextBlob returns a *polarity* and a *subjectivity* number.  Here we'll just extract the *polarity*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraph = tb.sentences\n",
    "\n",
    "i = -1\n",
    "for sentence in paragraph:\n",
    "    i += 1\n",
    "    pol = sentence.sentiment.polarity\n",
    "    if i == 0:\n",
    "        write_type = 'w'\n",
    "        with open('shunned.csv', write_type) as text_file:\n",
    "            header = 'number,polarity\\n'\n",
    "            text_file.write(str(header))\n",
    "    write_type = 'a'\n",
    "    with open('shunned.csv', write_type) as text_file:\n",
    "        newline = str(i) + ',' + str(pol) + '\\n'\n",
    "        text_file.write(str(newline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate a dataframe by pulling in that csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv('shunned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our data! First let's just look at how the sentiment polarity changes from sentence to sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.polarity.plot(figsize=(12,5), color='b', title='Sentiment Polarity for HP Lovecraft\\'s The Shunned House')\n",
    "plt.xlabel('Sentence number')\n",
    "plt.ylabel('Sentiment polarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very up and down from sentence to sentence!  Some dark sentences (the ones below 0.0 polarity), some positive sentences (greater than 0.0 polarity) but overall kind of hovers around 0.0 polarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that may be interesting to look at is how the senitment changes over the course of the book.  To examine that further, I'm going to create a new column in the dataframe which is the cumulative summation of the polarity rating, using the *cumsum()* pandas method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['cum_sum'] = df.polarity.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now let's plot the results-- How does the sentiment of Lovecraft's story change over the course of the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.cum_sum.plot(figsize=(12,5), color='r', \n",
    "                title='Sentiment Polarity cumulative summation for HP Lovecraft\\'s The Shunned House')\n",
    "plt.xlabel('Sentence number')\n",
    "plt.ylabel('Cumulative sum of sentiment polarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The climax of Lovecraft's story appears to be around sentence 255 or so.  Things really drop off at that point and get dark, according to the TextBlob sentiment analysis.\n",
    "\n",
    "What's the dataframe look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some basic statistical information about sentence seniments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, let's just see what TextBlob thinks are the most negatively polar sentences in the short story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df[df.polarity < -0.5].index:\n",
    "    print i, tb.sentences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = re.findall(r'\\w+', open('lovecraft.txt').read().lower())\n",
    "collections.Counter(words).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick peak at word frequencies by using the re and collections library.  Here we'll use the *Counter()* and *most_common()* methods to return a list of tuples of the most common words in the story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = re.findall(r'\\w+', ushunned.lower())\n",
    "common = collections.Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_freq = pd.DataFrame(common, columns=['word', 'freq'])\n",
    "df_freq.set_index('word').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
